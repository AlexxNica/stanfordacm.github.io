---
layout: default
title: ACM Winter Hackathon 2014
id: winterhack14
---

<section class="leadin">
<h1><em>ACM Winter Hackathon, 2014</em></h1>
</section>

<section class="schedule">
  <h2><em>Winners</em></h2>
  <h3>
    <span>First Place</span>
    <span class="hackathonPrize">| $1000</span>
  </h3>
  <div>
    <span><a href="http://chatternets.herokuapp.com">Chatternets</a></span>
    <span>Sophia Westwood and Brie Bunge</span>
    <p>
      A WebRTC project that transforms websites into virtual meeting places by
      letting you video chat while browsing the internet. When you click our
      bookmarklet in your browser bar, you join a live video chat with others
      viewing the same webpage -- a chatternet!
    </p>
  </div>
  <h3>
    <span>Second Place</span>
    <span class="hackathonPrize">| $500</span>
  </h3>
  <div>
    <span>Bablefish</span>
    <span>Ray Zhou, Yushi Wang, and Howon Lee</span>
    <p>
      Babelfish is a wearable computing device that acts as an instantaneous
      translator. It is fully voice commanded and allows its wearer to speak in
      any language of his/her choosing. It leverages the power of new web APIs,
      such as SpeechTranslation and WebSpeech.
    </p>
  </div>
  <h3>
    <span>Third Place</span>
    <span class="hackathonPrize">| $250, Best use of Microsoft APIs - XBox
      One</span>
  </h3>
  <div>
    <span><a href="http://influx.azurewebsites.net">Influx</a></span>
    <span>Aaron Brown, Varun Ramesh, and Lauises Puah</span>
    <p>
      Influx is an abstracted platform for building data analysis pipelines. Users
      work with abstract notions of sources, data operations, and visualizations,
      connecting elements in an intuitive flowchart. Instead of having decentralized
      directories of scripts that are difficult to maintain, Influx allows companies
      to build their data analysis into a single-cohesive platform, with real-time
      collaboration and an accessible web-based interface.
    </p>
  </div>
  <h3>
    <span>Most Social Good</span>
    <span class="hackathonPrize">| Dinner with judges, Automatic qualification for BASES
      Social-E Challenge</span>
  </h3>
  <div>
    <span>OPTin</span>
    <span>Grace</span>
    <p>
      Turbotax for Optional Practical Training applications
    </p>
  </div>
</section>

<section class="schedule">
  <h2><em>Participants</em></h2>
  <div>
    <span>Team Ratchet</span>
    <span>Mario Chris and Elijah Williams</span>
    <p>
      Outur Space, a medium through which Stanford students are able to find and
      provide open rooms to use for the night across campus residences.
    </p>
  </div>
  <div>
    <span>LegacyLabs</span>
    <span>Mike Yu, Kevin Moody, Aaron Zweig, and Dennis Xu</span>
    <p>
      Rocket - a new age machine learning productivity app that leverages
      passive data collection from iOS to schedule worktime to help users meet
      deadlines.
    </p>
  </div>
  <div>
    <span>Soft Stroke</span>
    <span>Sam Beder, Jay Hack, and Ankit Kumar</span>
    <p>
      We are using a PrimeSense camera (fancy version of a kinect) in order to
      make a natural, gesture-based interface for desktop computers. We have
      focused our efforts on creating methods for computer navigation that
      minimize the amount of stress one's body incurs (a well-known problem
      with 'minority report'-style interfaces) while simultaneously offering as
      much dexterity as possible. In particular, we have developed three
      different 'modes' through which one can interact with their computer,
      each optimized for a different set of tasks and demands. The most
      'natural,' or effortless, mode, in which one's arms hang loosely by their
      sides and small movements result in precise navigations, is made possible
      by a novel approach: we assigned a 'gravitational pull' to salient
      elements of one's desktop, such as files and folders, in order to guide
      their low-resolution attempts at moving the cursor. In addition, we made
      extensive use of machine learning; this allowed us to fully automate the
      transition between interface 'modes' (via pose detection) and also
      allowed for arbitrary gestures to map to hot-keys. As of this writing, we
      are working on adapting the gesture recognition to work with and
      manipulate 'Divvy,' a program aimed at intuitive window management in
      desktop interfaces. Though there remain tasks for which the traditional
      desktop computer interface is still better optimized (text-heavy web
      browsing, etc), we believe we have made the task of controlling a
      computer without a keyboard or mouse for extended periods of time
      feasible.
    </p>
  </div>
  <div>
    <span>alPAKA</span>
    <span>Alanna Tempest, Keenon Werling, Amy Bearman, and Pavitra Rengarajan</span>
    <p>
      We are working on a framework to create a slideshow with pictures/text
      and share it with friends.  It could have several applications, from
      serving as a way to communicate with family members far from home to
      making tutorials.
    </p>
  </div>
  <div>
    <span>Lediur</span>
    <span>Derrick Liu</span>
    <p>
      Making music requests better.
    </p>
  </div>
  <div>
    <span>Lost Trees</span>
    <span>Puneeth Gadangi, Silviana Ilcus, Kensen Shi, and Lisa Wang</span>
    <p>
      We are making a Lost &amp; Found online center for the Stanford community,
      and building it off the Microsoft Azure to-do list.
    </p>
  </div>
  <div>
    <span>Bmail</span>
    <span>Michael Fischer</span>
    <p>
      Email over Bitcoin.
    </p>
  </div>
  <div>
    <span>Gunship</span>
    <span>Luke Allen</span>
    <p>
      A 3D Android game, with several unique features.
    </p>
  </div>
</section>
